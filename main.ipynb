{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\igora\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\igora\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\igora\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\igora\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importação de Bibliotecas\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "\n",
    "## Manipulacao de Dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Pre processamento\n",
    "import ast\n",
    "import nltk\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import contractions, re, emoji\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "## Extracao de Atributos\n",
    "from scipy import spatial\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "## Classificadores\n",
    "import tensorflow as tf \n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, matthews_corrcoef, f1_score, classification_report\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import GRU, Bidirectional, Dropout, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import transformers\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import pipeline\n",
    "from keras.optimizers import Adam \n",
    "from keras.losses import SparseCategoricalCrossentropy \n",
    "from keras.metrics import SparseCategoricalAccuracy\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "\n",
    "## Visualizacao\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaçãoca de Dados\n",
    "test = pd.read_csv(\"data/tweets_labelled.csv\", sep=\";\")\n",
    "train = pd.read_csv(\"data/tweets_remaining.csv\", sep=\";\")\n",
    "\n",
    "test.drop(columns=[\"id\"], inplace=True)\n",
    "train.drop(columns=[\"id\"], inplace=True)\n",
    "\n",
    "train.rename(columns={\"full_text\": \"text\"}, inplace=True)\n",
    "\n",
    "data = pd.concat([train, test])\n",
    "data[\"created_at\"] = pd.to_datetime(data[\"created_at\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desenvolvendo a estrutura\n",
    "\n",
    "## Pre processamento\n",
    "\n",
    "Ajuste dos dados para modelagem, seguindo as seguintes etapas:\n",
    "- Limpeza Textual\n",
    "- Formatacao para analise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza Textual\n",
    "\n",
    "Ao analisar se todos os Tweets respeitam o limite de 280 caracteres, oberva-se que muitos passam desse limite. Olhando cada Tweet, percebe-se que isso deve-se aos links, aos @ de resposta, marcações de texto HTML, adições de ajustes do prórprio Twetter e ticker referenciados. Com isso, tais elemenentos devem ser retirados, deixando somente texto e emojis. Os tickers serão guardados em uma lista a parte.\n",
    "\n",
    "Por fim, importante lidar com os Emojis. Para tal será usado a biblioteca emoji, ao qual conseguirá realizar a tradução do emoji para uma palavra. Ainda, importante retirar as contracoes, expandido-as\n",
    "\n",
    "Importante notar que mesmo após os ajustes, ainda passará por 280, mas por pouco, devido a espaços ou detalhes do tipo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste da estrutura\n",
    "\n",
    "data[\"text_len\"] = [len(txt) for txt in data[\"text\"]]\n",
    "\n",
    "noAt = r'@[^\\s]+' # Retirar os @\n",
    "noLnk = r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)' # Retirar os Links\n",
    "noHash = r'#' # Retirar #\n",
    "noRT = r'^RT' # Retirar RT\n",
    "noE = r'\\&amp;' # Retirar & \n",
    "noNum = r'\\s\\S*[0-9]+\\S*' # Retirar numeros\n",
    "nos = r'|'.join((noAt, noLnk, noHash, noRT, noE, noNum))\n",
    "\n",
    "text_twtclean = [re.sub(nos,'',twt) for twt in data[\"text\"]]\n",
    "text_twtclean = [re.sub(r'(\\n)+',' ',twt) for twt in text_twtclean] # Trocando newline por espaco\n",
    "\n",
    "# Stocks Relacionadas\n",
    "text_stocks = []\n",
    "for twt in text_twtclean:\n",
    "    text_stocks.append(re.findall(r'\\$[A-Z]+',twt))\n",
    "data[\"tickers\"] = text_stocks\n",
    "text_twtclean = [re.sub(r'\\$[A-Z]+|^ | $','',twt) for twt in text_twtclean]\n",
    "\n",
    "# Emoji/Emoticons para palavras\n",
    "text_twtclean = [re.sub(r':|[ ]+', ' ', emoji.demojize(twt)) for twt in text_twtclean]\n",
    "\n",
    "# Expandindo contracoes\n",
    "text_twtclean = [contractions.fix(twt) for twt in text_twtclean]\n",
    "\n",
    "# Ajuste finais de espaco e pontuacao\n",
    "text_twtclean = [re.sub(r'[^\\w\\s]','', twt) for twt in text_twtclean]\n",
    "text_twtclean = [re.sub(r'^ | $','',twt) for twt in text_twtclean]\n",
    "text_twtclean = [re.sub(r' [ ]+',' ',twt) for twt in text_twtclean]\n",
    "\n",
    "data[\"text_final\"] = [text.lower() for text in text_twtclean]\n",
    "data[\"test_final_len\"] = [len(twt) for twt in text_twtclean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatacao para analise\n",
    "\n",
    "Para tal, realiza-se os seguintes processos:\n",
    "- Tokenizacao\n",
    "- Remocao de Stop Words\n",
    "- Lemmatization\n",
    "- Word Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\igora\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Construindo estrutura\n",
    "\n",
    "def tokenizacao(DATASOURCE):\n",
    "    df = DATASOURCE\n",
    "\n",
    "    ## Tokenizacao\n",
    "    tk = WhitespaceTokenizer()\n",
    "\n",
    "    tokens_src = [tk.tokenize(twt.lower()) for twt in df[\"text_final\"]]\n",
    "\n",
    "    ## Stop Words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    base = tokens_src\n",
    "    tokens_src = []\n",
    "    for tokens in base:\n",
    "        tokens_src.append([tkn for tkn in tokens if not tkn.lower() in stop_words])\n",
    "\n",
    "    ## Lemmatization\n",
    "    wnl = WordNetLemmatizer()\n",
    "\n",
    "    base = tokens_src\n",
    "    tokens_src = []\n",
    "    for tokens in base:\n",
    "        tokens_src.append([wnl.lemmatize(tkn) for tkn in tokens])\n",
    "\n",
    "    df[\"tokens\"] = tokens_src\n",
    "\n",
    "    return df\n",
    "\n",
    "def index_tokens(DATASOURCE):\n",
    "    df = DATASOURCE\n",
    "    \n",
    "    keys = list(set([item for sublist in list(df.tokens) for item in sublist]))\n",
    "    val = [i for i in range(0,len(keys))]\n",
    "    word_index = dict([(k, v) for k, v in zip(keys, val)])\n",
    "\n",
    "    def trans_index(lst):\n",
    "        return [word_index[item] for item in lst]\n",
    "    \n",
    "    df[\"tokens_index\"] = df.tokens.apply(lambda x: trans_index(x))\n",
    "\n",
    "    return df\n",
    "\n",
    "data = tokenizacao(data)\n",
    "data[\"created_at\"] = pd.to_datetime(data[\"created_at\"])\n",
    "data.to_csv('data/twitter_tokens.csv', index=False)\n",
    "\n",
    "data_orig = data[~data[\"sentiment\"].isnull()]\n",
    "data_orig.dropna(subset=['text_final'], inplace=True)\n",
    "data_orig.to_csv('data/twitter_labbeled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "## Troca baseada em contextualização - BERT\n",
    "\n",
    "Por meio da biblioteca NLPAug, foi possível implemetnar uma técnica de Data Augmentation baseado na troca de determinadas palavras em uma sentença em seus vizinhos no espaço gerado pelo modelo pré-treinado de BERT-uncased-base. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpaug.augmenter.word.context_word_embs import ContextualWordEmbsAug\n",
    "\n",
    "def textattack_data_augment(data, target, texattack_augmenter):\n",
    "\n",
    "  aug_data = []\n",
    "  aug_label = []\n",
    "  for text, label in zip(data, target):\n",
    "    aug_list = texattack_augmenter.augment(text, n=3, num_thread=5)\n",
    "\n",
    "    aug_data.append(text)\n",
    "    aug_label.append(label)\n",
    "\n",
    "    aug_data.extend(aug_list)\n",
    "    aug_label.extend([label]*len(aug_list))\n",
    "\n",
    "  return aug_data, aug_label\n",
    "\n",
    "aug = ContextualWordEmbsAug()\n",
    "aug_data, aug_lable = textattack_data_augment(data_orig.text_final, data_orig.sentiment, aug)\n",
    "\n",
    "data_aug = pd.DataFrame(columns=[\"text_final\", \"sentiment\"])\n",
    "\n",
    "data_aug.text_final = aug_data\n",
    "data_aug.sentiment = aug_lable\n",
    "\n",
    "data_aug = tokenizacao(data_aug)\n",
    "data_aug = index_tokens(data_aug)\n",
    "data_aug.dropna(subset=['text_final'], inplace=True)\n",
    "data_aug.to_csv('data/twitter_aug.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Point\n",
    "\n",
    "Etapas acima podem ser pulados com o que já foi salvo em data/twitter_tokens.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\igora\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:13: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    data = pd.read_csv(\"data/twitter_tokens.csv\")\n",
    "\n",
    "    data_orig = pd.read_csv(\"data/twitter_labbeled.csv\")\n",
    "    data_orig.dropna(subset=['text_final'], inplace=True)\n",
    "\n",
    "    data_aug = pd.read_csv(\"data/twitter_aug.csv\")\n",
    "    data_aug.dropna(subset=['text_final'], inplace=True)\n",
    "\n",
    "    return data, data_orig, data_aug\n",
    "\n",
    "# Puxando dados\n",
    "data, data_orig, data_aug = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicação do modelo\n",
    "\n",
    "## Extração de Atributos\n",
    "\n",
    "Transição de dados qualitativas para dados quantitativas considerando os seguintes diferentes modelos:\n",
    "- TD-IDF (https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "- GloVe (https://nlp.stanford.edu/projects/glove/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções dos Extratores\n",
    "\n",
    "## TDIDF\n",
    "def TDIDF_extract(DATASOURCE, TEST, SPLIT_RATIO, CLASF_TYPE):\n",
    "    # Adaptando estruturas\n",
    "    X = DATASOURCE.text_final\n",
    "    X_test = TEST.text_final\n",
    "    if CLASF_TYPE == \"GRU\": \n",
    "      trans = {\"positive\": \"[1,0,0]\", \"neutral\": \"[0,1,0]\", \"negative\": \"[0,0,1]\"}\n",
    "      DATASOURCE = DATASOURCE.replace({\"sentiment\": trans})\n",
    "      TEST = TEST.replace({\"sentiment\": trans})\n",
    "      Y = np.array([np.array(ast.literal_eval(sublist)) for sublist in list(DATASOURCE.sentiment)])\n",
    "      Y_test = np.array([np.array(ast.literal_eval(sublist)) for sublist in list(TEST.sentiment)])\n",
    "    else:\n",
    "      trans = {\"positive\": 1, \"neutral\": 0, \"negative\": -1}\n",
    "      DATASOURCE = DATASOURCE.replace({\"sentiment\": trans})\n",
    "      TEST = TEST.replace({\"sentiment\": trans})\n",
    "      Y_test = TEST.sentiment\n",
    "      Y = DATASOURCE.sentiment\n",
    "    \n",
    "    # Separacao entre teste e treino\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X, Y, stratify = Y, test_size=SPLIT_RATIO)\n",
    "\n",
    "    # Aplicando TD-IDF\n",
    "    tfidf = TfidfVectorizer(use_idf=True)\n",
    "    tfidf.fit(list(X_train))\n",
    "\n",
    "    # Transformando entre token para representativo numerico\n",
    "    X_train = tfidf.transform(list(X_train))\n",
    "    X_val = tfidf.transform(list(X_val))\n",
    "    X_test = tfidf.transform(list(X_test))\n",
    "\n",
    "    # Adaptacao adicional para rede neural\n",
    "    X_train = normalize(X_train.toarray(), axis=0)\n",
    "    X_val = normalize(X_val.toarray(), axis=0)\n",
    "    X_test = normalize(X_test.toarray(), axis=0)\n",
    "    Y_val = np.array(Y_val)\n",
    "    Y_train = np.array(Y_train)\n",
    "    if CLASF_TYPE == \"GRU\": \n",
    "      X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "      X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
    "      X_test = X_test.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
    "\n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test\n",
    "\n",
    "def index_tokens(DATASOURCE):\n",
    "    df = DATASOURCE\n",
    "    \n",
    "    keys = list(set([item for sublist in list(df.tokens) for item in ast.literal_eval(sublist)]))\n",
    "    val = [i for i in range(0,len(keys))]\n",
    "    word_index = dict([(k, v) for k, v in zip(keys, val)])\n",
    "\n",
    "    def trans_index(lst):\n",
    "        return [word_index[item] for item in ast.literal_eval(lst)]\n",
    "    \n",
    "    df[\"tokens_index\"] = df.tokens.apply(lambda x: trans_index(x))\n",
    "\n",
    "    return df\n",
    "\n",
    "## GLOVE\n",
    "### Construcao do embedding\n",
    "def embedding(DATASOURCE):\n",
    "    # Matrix de Index para os Tokens usados\n",
    "    keys = list(set([item for sublist in list(DATASOURCE.tokens) for item in ast.literal_eval(sublist)]))\n",
    "    val = [i for i in range(0,len(keys))]\n",
    "    word_index = dict([(k, v) for k, v in zip(keys, val)])\n",
    "\n",
    "    # Contrucao do banco de dados\n",
    "    embeddings_dict = {}\n",
    "    with open(\"data/glove.twitter.27B.200d.txt\", 'r', encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], \"float32\")\n",
    "            embeddings_dict[word] = vector\n",
    "\n",
    "\n",
    "    # Construindo matriz de embeddings\n",
    "    emb_dim = vector.shape[0]\n",
    "    vocab_len = len(word_index)+1\n",
    "    embedding_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    oov_count = 0\n",
    "    oov_words = []\n",
    "    for word, idx in word_index.items():\n",
    "        if idx < vocab_len:\n",
    "            embedding_vector = embeddings_dict.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[idx] = embedding_vector\n",
    "            else:\n",
    "                oov_count += 1 \n",
    "                oov_words.append(word)\n",
    "\n",
    "    return embedding_matrix\n",
    "\n",
    "\n",
    "### Media de Embedding \n",
    "def mean_emb(EMBEDDING_MATRIX, DATA):\n",
    "    # Definindo estrutura\n",
    "    X = np.zeros((len(DATA.tokens_index), EMBEDDING_MATRIX[0].shape[0]))\n",
    "    tokens_index = [sublist for sublist in list(DATA.tokens_index)]\n",
    "    \n",
    "    # Encontrando a media de emb. para cada sentenca\n",
    "    n = 0\n",
    "    for tkns in tokens_index:\n",
    "      sent = []\n",
    "      for idx in tkns:\n",
    "        word = EMBEDDING_MATRIX[idx]\n",
    "        sent.append(word)\n",
    "      if len(sent) > 0:\n",
    "        sent = np.array(sent)\n",
    "        X[n] = sent.mean(axis=0)\n",
    "      n += 1\n",
    "\n",
    "    return X\n",
    "\n",
    "### Extracao por GLOVE\n",
    "def GLOVE_extract(DATASOURCE, TEST, SPLIT_RATIO, EMBEDDING_MATRIX, CLASF_TYPE):\n",
    "    # Construindo os indices\n",
    "    TOTAL = pd.concat([DATASOURCE, TEST], axis=0)\n",
    "    TOTAL = index_tokens(TOTAL)\n",
    "    DATASOURCE = TOTAL.iloc[:len(DATASOURCE)]\n",
    "    TEST = TOTAL.iloc[len(DATASOURCE):]\n",
    "\n",
    "    # Construindo as estruturas\n",
    "    if CLASF_TYPE == \"GRU\": \n",
    "      MAX_LEN = round(np.max([len(tkns) for tkns in DATASOURCE.tokens]))+1\n",
    "      X = pad_sequences([sublist for sublist in list(DATASOURCE.tokens_index)], maxlen=MAX_LEN)\n",
    "      X_test = pad_sequences([sublist for sublist in list(TEST.tokens_index)], maxlen=MAX_LEN)\n",
    "      trans = {\"positive\": \"[1,0,0]\", \"neutral\": \"[0,1,0]\", \"negative\": \"[0,0,1]\"}\n",
    "      DATASOURCE = DATASOURCE.replace({\"sentiment\": trans})\n",
    "      TEST = TEST.replace({\"sentiment\": trans})\n",
    "      Y = np.array([np.array(ast.literal_eval(sublist)) for sublist in list(DATASOURCE.sentiment)])\n",
    "      Y_test = np.array([np.array(ast.literal_eval(sublist)) for sublist in list(TEST.sentiment)])\n",
    "    else:\n",
    "      X = mean_emb(EMBEDDING_MATRIX, DATASOURCE)\n",
    "      X_test = mean_emb(EMBEDDING_MATRIX, TEST)\n",
    "      trans = {\"positive\": 1, \"neutral\": 0, \"negative\": -1}\n",
    "      DATASOURCE = DATASOURCE.replace({\"sentiment\": trans})\n",
    "      TEST = TEST.replace({\"sentiment\": trans})\n",
    "      Y = np.array(DATASOURCE.sentiment)\n",
    "      Y_test = np.array(TEST.sentiment)\n",
    "\n",
    "    # Separacao entre teste e treino\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X, Y, stratify = Y, test_size=SPLIT_RATIO)\n",
    "    \n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação\n",
    "\n",
    "Realizando a predição de sentimento para cada conjunto de tokens, a partir dos seguintes médodos:\n",
    "- Naive Bayes\n",
    "- SVC\n",
    "- GRU\n",
    "- BART (com fine-tunning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função dos Classificadores\n",
    "\n",
    "## Modelos tradicionais de classificação\n",
    "\n",
    "### Criando curva de aprendizado\n",
    "def plot_learning_curve(clasf, X, Y, CLASF_TYPE, EXTRACT_TYPE):\n",
    "    plt.figure()\n",
    "    plt.title(EXTRACT_TYPE, fontsize=16)\n",
    "    plt.suptitle(CLASF_TYPE, fontsize=16, y=1)\n",
    "\n",
    "    if CLASF_TYPE == 'SVC':\n",
    "        splits = 1\n",
    "    else:\n",
    "        splits = 5\n",
    "    cv = ShuffleSplit(n_splits=splits, test_size=0.2, random_state=0)\n",
    "    train_sizes, train_scores, val_scores = learning_curve(clasf, X, Y, cv=cv, n_jobs=-1)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    val_scores_mean = np.mean(val_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.plot(train_sizes, train_scores_mean, color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, val_scores_mean, color=\"g\", label=\"Validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "    return train_sizes, train_scores, val_scores\n",
    "\n",
    "### Modelo tradicional\n",
    "def trad_clasf(X_train, Y_train, X_val, Y_val, CLASF_TYPE, EXTRACT_TYPE):\n",
    "    if CLASF_TYPE == \"NB\":\n",
    "        model = GaussianNB()\n",
    "    elif CLASF_TYPE == \"SVC\":\n",
    "        model = svm.SVC()\n",
    "    \n",
    "    Y = np.concatenate((Y_train, Y_val))\n",
    "    X = np.concatenate((X_train, X_val))\n",
    "    train_sizes, train_scores, val_scores = plot_learning_curve(model, X, Y, CLASF_TYPE, EXTRACT_TYPE)\n",
    "    model_history = pd.DataFrame([train_sizes, train_scores, val_scores]).T\n",
    "    model_history.columns = ['sizes', 'train_scores', 'val_scores']\n",
    "\n",
    "    # Fitando o Modelo com os dados de Treinamento\n",
    "    model_result = model.fit(X_train, Y_train)\n",
    "\n",
    "    # Realizando as previsões\n",
    "    Y_val_pred = model.predict(X_val) # Predicao no conjunto de teste\n",
    "    Y_train_pred = model.predict(X_train) # Predicao no conjunto de treino\n",
    "\n",
    "    # Sumarizando os resultados\n",
    "    print(\"---- Resultados com os dados de teste ----\")\n",
    "    print(classification_report(Y_val_pred, Y_val))\n",
    "    print(\"---- Resultados com os dados de treino ----\")\n",
    "    print(classification_report(Y_train_pred, Y_train))\n",
    "\n",
    "    return model, model_history\n",
    "\n",
    "## Bi-GRU with Attention\n",
    "### source https://alvinntnu.github.io/python-notes/nlp/seq-to-seq-m21-sentiment-attention.html\n",
    "class Attention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units) # input x weights\n",
    "        self.W2 = tf.keras.layers.Dense(units) # hidden states h weights\n",
    "        self.V = tf.keras.layers.Dense(1) # V\n",
    "\n",
    "    def call(self, features, hidden):\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "          \n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = tf.nn.tanh(\n",
    "            self.W1(features) + self.W2(hidden_with_time_axis)) ## w[x, h]\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1) ## v tanh(w[x,h])\n",
    "          \n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * features ## attention_weights * x, right now the context_vector shape [batzh_size, max_length, hidden_size]\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "def GRU_clasf(X_train, Y_train, X_val, Y_val, EMBEDDING_MATRIX, EXTRACT_TYPE, EPOCHS, VAL_FREQ):\n",
    "    # Especificando a estrutura\n",
    "    if EXTRACT_TYPE == \"GLOVE\":\n",
    "        EMB_DIM = EMBEDDING_MATRIX[0].shape[0]\n",
    "        VOCAB_LEN = len(EMBEDDING_MATRIX)\n",
    "        MAX_LEN = X_train.shape[1]\n",
    "\n",
    "        sequence_input = Input(shape=(MAX_LEN,), dtype=\"int32\")\n",
    "        embedded_sequences = Embedding(VOCAB_LEN, EMB_DIM, weights = [EMBEDDING_MATRIX])(sequence_input)\n",
    "        gru = Bidirectional(GRU(256, return_sequences = True), name=\"bi_lstm_0\")(embedded_sequences)\n",
    "    elif EXTRACT_TYPE == 'TDIDF':\n",
    "        sequence_input = Input(batch_shape=(None, X_train.shape[1], 1))\n",
    "        gru = Bidirectional(GRU(64, return_sequences = True), name=\"bi_lstm_0\")(sequence_input)\n",
    "\n",
    "    (gru, forward_h, backward_h) = Bidirectional(GRU(128, return_sequences=True, return_state=True), name=\"bi_lstm_1\")(gru)\n",
    "    state_h = Concatenate()([forward_h, backward_h])\n",
    "    context_vector, attention_weights = Attention(10)(gru, state_h) # `lstm` the input features; `state_h` the hidden states from LSTM\n",
    "    dense1 = Dense(64, activation=\"relu\")(context_vector)\n",
    "    dropout = Dropout(0.6)(dense1)\n",
    "    dense2 = Dense(64, activation=\"relu\")(dropout)\n",
    "    output = Dense(3, activation=\"sigmoid\")(dense2)\n",
    "    model = keras.Model(inputs=sequence_input, outputs=output)\n",
    "\n",
    "    METRICS = [\n",
    "        keras.metrics.TruePositives(name='tp'),\n",
    "        keras.metrics.FalsePositives(name='fp'),\n",
    "        keras.metrics.TrueNegatives(name='tn'),\n",
    "        keras.metrics.FalseNegatives(name='fn'),\n",
    "        keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall'),\n",
    "        keras.metrics.AUC(name='auc'),\n",
    "    ]\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam',\n",
    "              metrics=METRICS)\n",
    "\n",
    "    model_history = model.fit(X_train,Y_train,\n",
    "                        epochs=EPOCHS,\n",
    "                        validation_data=(X_val, Y_val),\n",
    "                        validation_freq=VAL_FREQ, \n",
    "                        use_multiprocessing=True)\n",
    "\n",
    "    # Plotagem dos Resultados\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(range(EPOCHS), model_history.history['accuracy'])\n",
    "    plt.plot([i for i in range(VAL_FREQ, EPOCHS+VAL_FREQ, VAL_FREQ)], model_history.history['val_accuracy'])\n",
    "    plt.legend(['training_acc', 'validation_acc'])\n",
    "    plt.title('Bi-GRU - {}'.format(EXTRACT_TYPE))\n",
    "\n",
    "    return model, model_history\n",
    "\n",
    "## Transformer BERT\n",
    "## source https://towardsdatascience.com/sentiment-analysis-in-10-minutes-with-bert-and-hugging-face-294e8a04b671\n",
    "\n",
    "def SentimentDatasetMapFunction(input_ids, attn_masks, labels):\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attn_masks\n",
    "    }, labels\n",
    "\n",
    "def preprocessing_dataset(df, ids, masks, tokenizer):\n",
    "    for i, text in tqdm(enumerate(df['text_final'])):\n",
    "        tokenized_text = tokenizer.encode_plus(\n",
    "            text,\n",
    "            max_length=128, \n",
    "            truncation=True, \n",
    "            padding='max_length', \n",
    "            add_special_tokens=True,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "        ids[i, :] = tokenized_text.input_ids\n",
    "        masks[i, :] = tokenized_text.attention_mask\n",
    "    return ids, masks\n",
    "\n",
    "def BERT_clasf(DATASOURCE, EPOCHS, VAL_FREQ, SPLIT_RATIO):\n",
    "    BERT = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "    df = data_aug[~data_aug[\"sentiment\"].isnull()]\n",
    "    trans = {\"positive\": \"[1,0,0]\", \"neutral\": \"[0,1,0]\", \"negative\": \"[0,0,1]\"}\n",
    "    df.replace({\"sentiment\": trans}, inplace=True)\n",
    "    df.dropna(subset=['text_final'], inplace=True)\n",
    "\n",
    "    X_input_ids = np.zeros((len(df), 128))\n",
    "    X_attn_masks = np.zeros((len(df), 128))\n",
    "    X_input_ids, X_attn_masks = preprocessing_dataset(df, X_input_ids, X_attn_masks, tokenizer)\n",
    "    labels = [ast.literal_eval(sent) for sent in df.sentiment]\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X_input_ids, X_attn_masks, labels))\n",
    "    dataset = dataset.map(SentimentDatasetMapFunction)\n",
    "    dataset = dataset.shuffle(10000).batch(16, drop_remainder=True) \n",
    "\n",
    "    p = 1-SPLIT_RATIO\n",
    "    train_size = int((len(df)//16)*p)\n",
    "    training_dataset = dataset.take(train_size)\n",
    "    validation_dataset = dataset.skip(train_size)\n",
    "\n",
    "    input_ids = tf.keras.layers.Input(shape=(128,), name='input_ids', dtype='int32')\n",
    "    attn_masks = tf.keras.layers.Input(shape=(128,), name='attention_mask', dtype='int32')\n",
    "    bert_embds = BERT.bert(input_ids, attention_mask=attn_masks)[1]\n",
    "    intermediate_layer = tf.keras.layers.Dense(256, activation='relu', name='intermediate_layer')(bert_embds)\n",
    "    output_layer = tf.keras.layers.Dense(3, activation='sigmoid', name='output_layer')(intermediate_layer) \n",
    "\n",
    "    model = tf.keras.Model(inputs=[input_ids, attn_masks], outputs=output_layer)\n",
    "\n",
    "    optim = tf.keras.optimizers.Adam(learning_rate=1e-5, decay=1e-6)\n",
    "    loss_func = tf.keras.losses.CategoricalCrossentropy()\n",
    "    acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "\n",
    "    model.compile(optimizer=optim, loss=loss_func, metrics=[acc])\n",
    "\n",
    "    model_history = model.fit(\n",
    "        training_dataset,\n",
    "        validation_data=validation_dataset,\n",
    "        epochs=EPOCHS, \n",
    "        validation_freq=VAL_FREQ\n",
    "    )\n",
    "    \n",
    "    # Plotagem dos Resultados\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(range(EPOCHS), model_history.history['accuracy'])\n",
    "    plt.plot([i for i in range(VAL_FREQ, EPOCHS+VAL_FREQ, VAL_FREQ)], model_history.history['val_accuracy'])\n",
    "    plt.legend(['training_acc', 'validation_acc'])\n",
    "    plt.title('Accuracy')\n",
    "\n",
    "    return model, model_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Área de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções para aplicação de modelos\n",
    "\n",
    "def apply_model(DBtype, CLASF_TYPE, EXTRACT_TYPE=None, SPLIT_RATIO=None, EPOCHS=None, VAL_FREQ=None):\n",
    "    # Selecionando database\n",
    "    if DBtype == \"ORIGINAL\":\n",
    "        DB = data_orig\n",
    "        sample = DB[~DB[\"sentiment\"].isnull()].sample(frac = 0.8, replace=False)\n",
    "        test = DB[~DB.isin(sample)].dropna()\n",
    "    elif DBtype == \"AUGMENT\":\n",
    "        DB = data_aug\n",
    "        sample = data_aug.iloc[:4659]\n",
    "        test = data_aug.iloc[[i for i in range(4660, 5176) if i % 4 ==0], ]\n",
    "\n",
    "    # Definindo tipo de extrator\n",
    "    if EXTRACT_TYPE == \"TDIDF\":\n",
    "        embedding_matrix = None\n",
    "        X_train, Y_train, X_val, Y_val, X_test, Y_test = TDIDF_extract(sample, test, SPLIT_RATIO, CLASF_TYPE)\n",
    "    elif EXTRACT_TYPE == \"GLOVE\":\n",
    "        embedding_matrix = embedding(DATASOURCE=DB)\n",
    "        X_train, Y_train, X_val, Y_val, X_test, Y_test = GLOVE_extract(sample, test, SPLIT_RATIO, embedding_matrix, CLASF_TYPE)\n",
    "    \n",
    "    # Definindo tipo de classificador\n",
    "    if CLASF_TYPE == \"NB\" or CLASF_TYPE == \"SVC\":\n",
    "        model, model_hist = trad_clasf(X_train, Y_train, X_val, Y_val, CLASF_TYPE, EXTRACT_TYPE)\n",
    "    elif CLASF_TYPE == \"GRU\":\n",
    "        model, model_hist = GRU_clasf(X_train, Y_train, X_val, Y_val, embedding_matrix, EXTRACT_TYPE, EPOCHS, VAL_FREQ)\n",
    "    elif CLASF_TYPE == \"BERT\":\n",
    "        X_test = None\n",
    "        Y_test = None        \n",
    "        model, model_hist = BERT_clasf(sample, EPOCHS, VAL_FREQ, SPLIT_RATIO)\n",
    "\n",
    "    \n",
    "    Y_pred = model.predict(X_test)\n",
    "    #acc = accuracy_score(Y_test, Y_pred)\n",
    "    #mcc = matthews_corrcoef(Y_test, Y_pred)\n",
    "    #f1 = f1_score(Y_test, Y_pred, average='weighted')\n",
    "    #print(\"Obteve-se uma acc de {}\".format(acc))\n",
    "    #print(\"Obteve-se um mcc de {}\".format(mcc))\n",
    "    #print(\"Obteve-se um f1 de {}\".format(f1))\n",
    "\n",
    "    return  model, model_hist, X_test, Y_test, Y_pred\n",
    "        \n",
    "\n",
    "model, model_hist, X_test, Y_test, a = apply_model(\"ORIGINAL\", \"GRU\", \"GLOVE\", 0.33, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "5176it [00:01, 3303.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "216/216 [==============================] - 2068s 10s/step - loss: 0.9903 - accuracy: 0.5095 - val_loss: 0.7674 - val_accuracy: 0.6776\n",
      "Epoch 2/5\n",
      "216/216 [==============================] - 1954s 9s/step - loss: 0.7314 - accuracy: 0.6956 - val_loss: 0.5407 - val_accuracy: 0.7996\n",
      "Epoch 3/5\n",
      "216/216 [==============================] - 2075s 10s/step - loss: 0.5320 - accuracy: 0.7925 - val_loss: 0.3175 - val_accuracy: 0.8919\n",
      "Epoch 4/5\n",
      "216/216 [==============================] - 2860s 13s/step - loss: 0.3411 - accuracy: 0.8808 - val_loss: 0.1666 - val_accuracy: 0.9457\n",
      "Epoch 5/5\n",
      "216/216 [==============================] - 1864s 9s/step - loss: 0.2175 - accuracy: 0.9242 - val_loss: 0.0911 - val_accuracy: 0.9755\n",
      "0/129\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/129\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "2/129\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "3/129\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "4/129\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "5/129\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "6/129\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "7/129\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "8/129\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "9/129\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "10/129\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "11/129\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "12/129\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "13/129\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "14/129\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "15/129\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "16/129\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "17/129\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "18/129\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "19/129\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "20/129\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "21/129\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "22/129\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "23/129\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "24/129\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "25/129\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "26/129\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "27/129\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "28/129\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "29/129\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "30/129\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "31/129\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "32/129\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "33/129\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "34/129\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "35/129\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "36/129\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "37/129\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "38/129\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "39/129\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "40/129\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "41/129\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "42/129\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "43/129\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "44/129\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "45/129\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "46/129\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "47/129\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "48/129\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "49/129\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "50/129\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "51/129\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "52/129\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "53/129\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "54/129\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "55/129\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "56/129\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "57/129\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "58/129\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "59/129\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "60/129\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "61/129\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "62/129\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "63/129\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "64/129\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "65/129\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "66/129\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "67/129\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "68/129\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "69/129\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "70/129\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "71/129\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "72/129\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "73/129\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "74/129\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "75/129\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "76/129\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "77/129\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "78/129\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "79/129\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "80/129\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "81/129\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "82/129\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "83/129\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "84/129\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "85/129\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "86/129\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "87/129\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "88/129\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "89/129\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "90/129\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "91/129\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "92/129\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "93/129\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "94/129\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "95/129\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "96/129\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "97/129\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "98/129\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "99/129\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "100/129\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "101/129\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "102/129\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "103/129\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "104/129\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "105/129\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "106/129\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "107/129\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "108/129\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "109/129\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "110/129\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "111/129\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "112/129\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "113/129\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "114/129\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "115/129\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "116/129\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "117/129\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "118/129\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "119/129\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "120/129\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "121/129\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "122/129\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "123/129\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "124/129\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "125/129\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "126/129\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "127/129\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "128/129\n",
      "1/1 [==============================] - 0s 263ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def prepare_data(input_text, tokenizer):\n",
    "    token = tokenizer.encode_plus(\n",
    "        input_text,\n",
    "        max_length=128, \n",
    "        truncation=True, \n",
    "        padding='max_length', \n",
    "        add_special_tokens=True,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "    return {\n",
    "        'input_ids': tf.cast(token.input_ids, tf.float64),\n",
    "        'attention_mask': tf.cast(token.attention_mask, tf.float64)\n",
    "    }\n",
    "\n",
    "def make_prediction(model, processed_data):\n",
    "    result = (np.argmax(model.predict(processed_data)[0]) - 1)*-1\n",
    "    return result \n",
    "\n",
    "sample = data_orig[~data_orig[\"sentiment\"].isnull()].sample(frac = 0.9, replace=False)\n",
    "test = data_orig[~data_orig.isin(sample)].dropna()\n",
    "\n",
    "#sample = data_aug.iloc[:4659]\n",
    "#test = data_aug.iloc[[i for i in range(4660, 5176) if i % 4 ==0], ]\n",
    "\n",
    "model, model_hist = BERT_clasf(sample, 5, 1, 0.33)\n",
    "\n",
    "TOTAL = len(test.text_final)\n",
    "pred_sent = []\n",
    "stage = 0\n",
    "for tweet in test.text_final:\n",
    "    print(\"{}/{}\".format(stage, TOTAL))\n",
    "    processed_data = prepare_data(tweet, tokenizer)\n",
    "    result = make_prediction(model, processed_data=processed_data)\n",
    "    pred_sent.append(result)\n",
    "    stage = stage + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = {\"positive\": \"[1,0,0]\", \"neutral\": \"[0,1,0]\", \"negative\": \"[0,0,1]\"}\n",
    "test = test.replace({\"sentiment\": trans})\n",
    "Y_test = np.array([np.array(ast.literal_eval(sublist)) for sublist in list(test.sentiment)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "VAL_FREQ = 1\n",
    "\n",
    "sample = data_aug.iloc[:4659]\n",
    "test = data_aug.iloc[[i for i in range(4660, 5176) if i % 4 ==0], ]\n",
    "\n",
    "#sample = data_orig[~data_orig[\"sentiment\"].isnull()].sample(frac = 0.9, replace=False)\n",
    "#test = data_orig[~data_orig.isin(sample)].dropna()\n",
    "DB = sample\n",
    "\n",
    "X = DB.text_final\n",
    "X_test = test.text_final\n",
    "\n",
    "trans = {\"positive\": \"[1,0,0]\", \"neutral\": \"[0,1,0]\", \"negative\": \"[0,0,1]\"}\n",
    "DB = DB.replace({\"sentiment\": trans})\n",
    "test = test.replace({\"sentiment\": trans})\n",
    "Y = np.array([np.array(ast.literal_eval(sublist)) for sublist in list(DB.sentiment)])\n",
    "Y_test = np.array([np.array(ast.literal_eval(sublist)) for sublist in list(test.sentiment)])\n",
    "\n",
    "# Separacao entre teste e treino\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, stratify = Y, test_size=0.33)\n",
    "\n",
    "# Aplicando TD-IDF\n",
    "tfidf = TfidfVectorizer(use_idf=True)\n",
    "tfidf.fit(list(X_train))\n",
    "\n",
    "# Transformando entre token para representativo numerico\n",
    "X_train = tfidf.transform(list(X_train))\n",
    "X_val = tfidf.transform(list(X_val))\n",
    "X_test = tfidf.transform(list(X_test))\n",
    "\n",
    "# Adaptacao adicional para rede neural\n",
    "X_train = normalize(X_train.toarray(), axis=0)\n",
    "X_val = normalize(X_val.toarray(), axis=0)\n",
    "X_test = normalize(X_test.toarray(), axis=0)\n",
    "Y_val = np.array(Y_val)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_train.shape[1], 1)\n",
    "\n",
    "sequence_input = Input(batch_shape=(None, X_train.shape[1], 1))\n",
    "gru = Bidirectional(GRU(64, return_sequences = True), name=\"bi_lstm_0\")(sequence_input)\n",
    "\n",
    "(gru, forward_h, backward_h) = Bidirectional(GRU(128, return_sequences=True, return_state=True), name=\"bi_lstm_1\")(gru)\n",
    "state_h = Concatenate()([forward_h, backward_h])\n",
    "context_vector, attention_weights = Attention(10)(gru, state_h) # `lstm` the input features; `state_h` the hidden states from LSTM\n",
    "dense1 = Dense(64, activation=\"relu\")(context_vector)\n",
    "dropout = Dropout(0.6)(dense1)\n",
    "dense2 = Dense(64, activation=\"relu\")(dropout)\n",
    "output = Dense(3, activation=\"sigmoid\")(dense2)\n",
    "model = keras.Model(inputs=sequence_input, outputs=output)\n",
    "\n",
    "METRICS = [\n",
    "    keras.metrics.TruePositives(name='tp'),\n",
    "    keras.metrics.FalsePositives(name='fp'),\n",
    "    keras.metrics.TrueNegatives(name='tn'),\n",
    "    keras.metrics.FalseNegatives(name='fn'),\n",
    "    keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    keras.metrics.Precision(name='precision'),\n",
    "    keras.metrics.Recall(name='recall'),\n",
    "    keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=METRICS)\n",
    "\n",
    "model_history = model.fit(X_train,Y_train,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(X_val, Y_val),\n",
    "                    validation_freq=VAL_FREQ, \n",
    "                    use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 11s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.42935595, 0.34628192, 0.29512763],\n",
       "       [0.42952698, 0.3466663 , 0.29561543],\n",
       "       [0.4294278 , 0.3464432 , 0.29533222],\n",
       "       [0.42930225, 0.3461611 , 0.29497433],\n",
       "       [0.4293077 , 0.34617296, 0.29498965],\n",
       "       [0.42949447, 0.34659302, 0.2955226 ],\n",
       "       [0.42937827, 0.34633172, 0.2951909 ],\n",
       "       [0.42933658, 0.3462374 , 0.29507166],\n",
       "       [0.42944407, 0.34648007, 0.29537898],\n",
       "       [0.42946473, 0.3465261 , 0.2954376 ],\n",
       "       [0.42929518, 0.34614474, 0.2949538 ],\n",
       "       [0.42937756, 0.3463304 , 0.29518914],\n",
       "       [0.42943734, 0.34646466, 0.29535955],\n",
       "       [0.42951012, 0.34662813, 0.2955671 ],\n",
       "       [0.42942923, 0.34644637, 0.29533637],\n",
       "       [0.42945936, 0.346514  , 0.29542223],\n",
       "       [0.42935607, 0.34628117, 0.29512686],\n",
       "       [0.42947653, 0.34655273, 0.29547134],\n",
       "       [0.42946672, 0.34653074, 0.2954434 ],\n",
       "       [0.4294298 , 0.34644753, 0.29533795],\n",
       "       [0.4294332 , 0.34645537, 0.29534775],\n",
       "       [0.42945534, 0.3465053 , 0.2954111 ],\n",
       "       [0.4293973 , 0.34637493, 0.29524568],\n",
       "       [0.42948118, 0.34656325, 0.29548472],\n",
       "       [0.42938572, 0.34634852, 0.2952123 ],\n",
       "       [0.42937762, 0.34633046, 0.29518923],\n",
       "       [0.42945525, 0.34650505, 0.29541078],\n",
       "       [0.4293903 , 0.3463588 , 0.29522538],\n",
       "       [0.4293479 , 0.34626365, 0.29510444],\n",
       "       [0.42947072, 0.34653962, 0.29545474],\n",
       "       [0.4294193 , 0.3464239 , 0.295308  ],\n",
       "       [0.42938954, 0.34635708, 0.29522315],\n",
       "       [0.42940024, 0.34638113, 0.2952536 ],\n",
       "       [0.42938486, 0.34634638, 0.29520956],\n",
       "       [0.4294181 , 0.34642148, 0.29530475],\n",
       "       [0.42939213, 0.34636328, 0.29523078],\n",
       "       [0.42937866, 0.3463325 , 0.29519203],\n",
       "       [0.42948103, 0.3465629 , 0.29548424],\n",
       "       [0.42944515, 0.34648165, 0.29538125],\n",
       "       [0.4293972 , 0.3463742 , 0.2952449 ],\n",
       "       [0.42949438, 0.3465931 , 0.2955225 ],\n",
       "       [0.42939478, 0.34636858, 0.295238  ],\n",
       "       [0.42940667, 0.34639594, 0.29527226],\n",
       "       [0.42948583, 0.34657362, 0.2954979 ],\n",
       "       [0.4294096 , 0.3464024 , 0.2952805 ],\n",
       "       [0.42931622, 0.3461917 , 0.29501325],\n",
       "       [0.42937636, 0.3463277 , 0.29518574],\n",
       "       [0.42937416, 0.34632266, 0.29517934],\n",
       "       [0.42930296, 0.34616268, 0.2949764 ],\n",
       "       [0.42952377, 0.34665906, 0.29560632],\n",
       "       [0.42942518, 0.34643742, 0.295325  ],\n",
       "       [0.42944983, 0.34649286, 0.2953952 ],\n",
       "       [0.4294476 , 0.34648755, 0.2953888 ],\n",
       "       [0.4294397 , 0.34647006, 0.29536638],\n",
       "       [0.42945144, 0.3464969 , 0.29540017],\n",
       "       [0.42939845, 0.34637746, 0.29524893],\n",
       "       [0.4294407 , 0.3464726 , 0.29536942],\n",
       "       [0.4294524 , 0.34649834, 0.2954024 ],\n",
       "       [0.42944852, 0.3464895 , 0.29539135],\n",
       "       [0.42938864, 0.34635556, 0.29522094],\n",
       "       [0.42947948, 0.34655973, 0.29548007],\n",
       "       [0.42948917, 0.34658143, 0.29550764],\n",
       "       [0.42925793, 0.34606165, 0.29484808],\n",
       "       [0.42952377, 0.34665903, 0.29560632],\n",
       "       [0.4294981 , 0.3466015 , 0.29553297],\n",
       "       [0.42923298, 0.34600464, 0.29477593],\n",
       "       [0.42940125, 0.34638357, 0.29525658],\n",
       "       [0.4294626 , 0.3465214 , 0.2954316 ],\n",
       "       [0.42934442, 0.3462554 , 0.29509428],\n",
       "       [0.4294411 , 0.34647316, 0.2953704 ],\n",
       "       [0.4294322 , 0.34645325, 0.29534504],\n",
       "       [0.42936102, 0.34629261, 0.2951416 ],\n",
       "       [0.42941684, 0.34641913, 0.29530144],\n",
       "       [0.42937136, 0.346316  , 0.2951712 ],\n",
       "       [0.4294237 , 0.3464343 , 0.29532084],\n",
       "       [0.42943788, 0.34646624, 0.2953614 ],\n",
       "       [0.42938268, 0.3463419 , 0.2952037 ],\n",
       "       [0.4294362 , 0.34646204, 0.2953564 ],\n",
       "       [0.4294354 , 0.34646058, 0.29535422],\n",
       "       [0.429373  , 0.3463201 , 0.2951761 ],\n",
       "       [0.4293416 , 0.34624946, 0.29508653],\n",
       "       [0.42929778, 0.34615013, 0.29496095],\n",
       "       [0.42943764, 0.3464654 , 0.29536048],\n",
       "       [0.42950323, 0.34661293, 0.29554763],\n",
       "       [0.42938468, 0.34634668, 0.29520962],\n",
       "       [0.42936623, 0.3463049 , 0.29515687],\n",
       "       [0.42938858, 0.34635517, 0.29522058],\n",
       "       [0.42946684, 0.34653124, 0.29544398],\n",
       "       [0.42942142, 0.3464292 , 0.2953144 ],\n",
       "       [0.42929968, 0.34615484, 0.29496673],\n",
       "       [0.42941684, 0.3464181 , 0.29530084],\n",
       "       [0.42935044, 0.34626895, 0.29511148],\n",
       "       [0.42943633, 0.34646234, 0.29535666],\n",
       "       [0.42942178, 0.34643012, 0.29531553],\n",
       "       [0.42939308, 0.3463654 , 0.29523355],\n",
       "       [0.42937872, 0.34633276, 0.29519236],\n",
       "       [0.42937687, 0.34632853, 0.29518697],\n",
       "       [0.42938507, 0.346347  , 0.29521042],\n",
       "       [0.42941368, 0.34641117, 0.2952919 ],\n",
       "       [0.42936212, 0.34629476, 0.2951438 ],\n",
       "       [0.42938927, 0.3463571 , 0.29522285],\n",
       "       [0.4294243 , 0.34643543, 0.29532236],\n",
       "       [0.4294321 , 0.34645274, 0.29534435],\n",
       "       [0.42944354, 0.3464789 , 0.29537746],\n",
       "       [0.4294367 , 0.346463  , 0.29535764],\n",
       "       [0.4294733 , 0.34654564, 0.29546228],\n",
       "       [0.4294583 , 0.34651154, 0.29541925],\n",
       "       [0.4294586 , 0.3465121 , 0.29541978],\n",
       "       [0.42947802, 0.34655595, 0.29547554],\n",
       "       [0.42939305, 0.34636495, 0.29523316],\n",
       "       [0.42947218, 0.34654313, 0.29545897],\n",
       "       [0.42943865, 0.3464673 , 0.29536304],\n",
       "       [0.4295049 , 0.34661674, 0.2955525 ],\n",
       "       [0.42948592, 0.3465738 , 0.2954981 ],\n",
       "       [0.4293955 , 0.34637052, 0.29524022],\n",
       "       [0.42947707, 0.346554  , 0.29547295],\n",
       "       [0.42941767, 0.34642014, 0.29530334],\n",
       "       [0.42942375, 0.3464343 , 0.29532096],\n",
       "       [0.4293801 , 0.34633642, 0.29519665],\n",
       "       [0.42945865, 0.3465126 , 0.29542035],\n",
       "       [0.42895284, 0.34537363, 0.29397723],\n",
       "       [0.42944285, 0.34647727, 0.29537547],\n",
       "       [0.42945588, 0.3465063 , 0.29541245],\n",
       "       [0.42945927, 0.3465139 , 0.29542205],\n",
       "       [0.42949554, 0.34659562, 0.29552567],\n",
       "       [0.42928922, 0.34613198, 0.29493737],\n",
       "       [0.4293224 , 0.34620598, 0.29503116],\n",
       "       [0.4295087 , 0.34662494, 0.29556304],\n",
       "       [0.4294818 , 0.34656456, 0.29548636]], dtype=float32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for tst in Y_test:\n",
    "    result.append(np.argmax(tst)*-1 + 1)\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "comp = []\n",
    "for pred in Y_pred:\n",
    "    comp.append(np.argmax(pred)*-1 + 1)\n",
    "\n",
    "\n",
    "acc = accuracy_score(result, comp)\n",
    "mcc = matthews_corrcoef(result, comp)\n",
    "f1 = f1_score(result, comp, average='weighted')\n",
    "print(\"Obteve-se uma acc de {}\".format(acc))\n",
    "print(\"Obteve-se um mcc de {}\".format(mcc))\n",
    "print(\"Obteve-se um f1 de {}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units) # input x weights\n",
    "        self.W2 = tf.keras.layers.Dense(units) # hidden states h weights\n",
    "        self.V = tf.keras.layers.Dense(1) # V\n",
    "\n",
    "    def call(self, features, hidden):\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "          \n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = tf.nn.tanh(\n",
    "            self.W1(features) + self.W2(hidden_with_time_axis)) ## w[x, h]\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1) ## v tanh(w[x,h])\n",
    "          \n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * features ## attention_weights * x, right now the context_vector shape [batzh_size, max_length, hidden_size]\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "\n",
    "#sample = data_aug.iloc[:4659]\n",
    "#test = data_aug.iloc[[i for i in range(4660, 5176) if i % 4 ==0], ]\n",
    "\n",
    "sample = data_orig[~data_orig[\"sentiment\"].isnull()].sample(frac = 0.9, replace=False)\n",
    "test = data_orig[~data_orig.isin(sample)].dropna()\n",
    "DB = sample\n",
    "\n",
    "TOTAL = pd.concat([DB, test], axis=0)\n",
    "TOTAL = index_tokens(TOTAL)\n",
    "DB = TOTAL.iloc[:len(DB)]\n",
    "test = TOTAL.iloc[len(DB):]\n",
    "EMBEDDING_MATRIX = embedding(DATASOURCE=TOTAL)\n",
    "MAX_LEN = round(np.max([len(tkns) for tkns in DB.tokens]))+1\n",
    "X = pad_sequences([sublist for sublist in list(DB.tokens_index)], maxlen=MAX_LEN)\n",
    "X_test = pad_sequences([sublist for sublist in list(test.tokens_index)], maxlen=X.shape[1])\n",
    "trans = {\"positive\": \"[1,0,0]\", \"neutral\": \"[0,1,0]\", \"negative\": \"[0,0,1]\"}\n",
    "DB = DB.replace({\"sentiment\": trans})\n",
    "test = test.replace({\"sentiment\": trans})\n",
    "Y = np.array([np.array(ast.literal_eval(sublist)) for sublist in list(DB.sentiment)])\n",
    "Y_test = np.array([np.array(ast.literal_eval(sublist)) for sublist in list(test.sentiment)])\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, stratify = Y, test_size=0.33)\n",
    "\n",
    "EMB_DIM = EMBEDDING_MATRIX[0].shape[0]\n",
    "VOCAB_LEN = len(EMBEDDING_MATRIX)\n",
    "MAX_LEN = X_train.shape[1]\n",
    "RNN_CELL_SIZE = 32\n",
    "\n",
    "sequence_input = Input(shape=(MAX_LEN,), dtype=\"int32\")\n",
    "embedded_sequences = Embedding(VOCAB_LEN, EMB_DIM, weights = [EMBEDDING_MATRIX])(sequence_input)\n",
    "gru = Bidirectional(GRU(128, return_sequences = True), name=\"bi_lstm_0\")(embedded_sequences)\n",
    "\n",
    "# Getting our LSTM outputs\n",
    "(gru, forward_h, backward_h) = Bidirectional(GRU(128, return_sequences=True, return_state=True), name=\"bi_lstm_1\")(gru)\n",
    "state_h = Concatenate()([forward_h, backward_h])\n",
    "context_vector, attention_weights = Attention(10)(gru, state_h) # `lstm` the input features; `state_h` the hidden states from LSTM\n",
    "dense1 = Dense(64, activation=\"relu\")(context_vector)\n",
    "dropout = Dropout(0.5)(dense1)\n",
    "dense2 = Dense(64, activation=\"relu\")(dropout)\n",
    "output = Dense(3, activation=\"sigmoid\")(dense2)\n",
    "  \n",
    "model = keras.Model(inputs=sequence_input, outputs=output)\n",
    "\n",
    "METRICS = [\n",
    "    keras.metrics.TruePositives(name='tp'),\n",
    "    keras.metrics.FalsePositives(name='fp'),\n",
    "    keras.metrics.TrueNegatives(name='tn'),\n",
    "    keras.metrics.FalseNegatives(name='fn'),\n",
    "    keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    keras.metrics.Precision(name='precision'),\n",
    "    keras.metrics.Recall(name='recall'),\n",
    "    keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=METRICS)\n",
    "\n",
    "\n",
    "EPOCHS = 10\n",
    "history = model.fit(X_train,Y_train,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(X_val, Y_val), \n",
    "                    validation_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Y_pred[0])*-1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for tst in Y_test:\n",
    "    result.append(np.argmax(tst)*-1 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x1db91e848c8>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 9s 2s/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = []\n",
    "for pred in Y_pred:\n",
    "    comp.append(np.argmax(pred)*-1 + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteve-se uma acc de 0.4108527131782946\n",
      "Obteve-se um mcc de 0.0\n",
      "Obteve-se um f1 de 0.23928784393900673\n"
     ]
    }
   ],
   "source": [
    "\n",
    "acc = accuracy_score(result, comp)\n",
    "mcc = matthews_corrcoef(result, comp)\n",
    "f1 = f1_score(result, comp, average='weighted')\n",
    "print(\"Obteve-se uma acc de {}\".format(acc))\n",
    "print(\"Obteve-se um mcc de {}\".format(mcc))\n",
    "print(\"Obteve-se um f1 de {}\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relação com o mercado\n",
    "\n",
    "Analisar existência de correlação entre os movimentos diários do mercado com as análise de sentimento. Para tal, serão considerados para o movimento de mercado:\n",
    "- S&P500\n",
    "- Amazon.com\n",
    "- Apple\n",
    "- META\n",
    "- Microsoft\n",
    "\n",
    "## Predição dos sentimentos\n",
    "\n",
    "Dentro o universo de tweets não rotulados, estes serão rotulados por meio do melhor modelo. Com isso, tais dados passarão a ser rotulados. Os resultados serão agrupados de forma diária, com positivo = 1, neutro = 0 e negativo = -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_clasf = load_model('data/bert')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def prepare_data(input_text, tokenizer):\n",
    "    token = tokenizer.encode_plus(\n",
    "        input_text,\n",
    "        max_length=128, \n",
    "        truncation=True, \n",
    "        padding='max_length', \n",
    "        add_special_tokens=True,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "    return {\n",
    "        'input_ids': tf.cast(token.input_ids, tf.float64),\n",
    "        'attention_mask': tf.cast(token.attention_mask, tf.float64)\n",
    "    }\n",
    "\n",
    "def make_prediction(model, processed_data):\n",
    "    result = (np.argmax(sent_clasf.predict(processed_data)[0]) - 1)*-1\n",
    "    return result \n",
    "\n",
    "tweets = data[pd.isna(data.sentiment)]\n",
    "tweets = tweets[~pd.isna(tweets.text_final)]\n",
    "\n",
    "tickers = [ast.literal_eval(lst) for lst in list(tweets.tickers)]\n",
    "matchers = ['$SPX', '$SPY', '$AAPL', '$AMZN', '$FB', '$MSFT']\n",
    "matching = [any(tck in lst for tck in matchers) for lst in tickers]\n",
    "tweets = tweets[np.array(matching).astype(bool)]\n",
    "\n",
    "tweets = tweets.sample(60000)\n",
    "TOTAL = len(tweets.text_final)\n",
    "\n",
    "pred_sent = []\n",
    "stage = 0\n",
    "for tweet in tweets.text_final:\n",
    "    print(\"{}/{}\".format(stage, TOTAL))\n",
    "    processed_data = prepare_data(tweet, tokenizer)\n",
    "    result = make_prediction(sent_clasf, processed_data=processed_data)\n",
    "    pred_sent.append(result)\n",
    "    stage = stage + 1\n",
    "\n",
    "tweets[\"sentiment\"] = pred_sent\n",
    "\n",
    "tweets.to_excel('data/tweets_clasf.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de Correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_analy(COMP, TCKRS):\n",
    "    # Considerar somente para o ticker COMP\n",
    "    clf = pd.read_csv(\"data/tweets_clasf.csv\")\n",
    "    clf.created_at = pd.to_datetime(clf.created_at)\n",
    "    matching = [any(tck in lst for tck in TCKRS) for lst in clf.tickers]\n",
    "    clf = clf[np.array(matching).astype(bool)]\n",
    "    clf = clf.sort_values(by=[\"created_at\"], ascending=True)\n",
    "    clf = clf.groupby(by=clf[\"created_at\"].dt.date).sum().reset_index()[['created_at', 'sentiment']]\n",
    "    clf.created_at = pd.to_datetime(clf[\"created_at\"]) \n",
    "\n",
    "    # Considerando os retornos diarios para COMP\n",
    "    rtns = pd.read_csv(\"data/sp_hist_daily.csv\", sep=';')\n",
    "    rtns[\"created_at\"] = pd.to_datetime(rtns[\"created_at\"], dayfirst=True)\n",
    "    rtns = rtns.sort_values(by=[\"created_at\"], ascending=True)\n",
    "    rtns = rtns[[\"created_at\", COMP]]\n",
    "\n",
    "    # Unificando os dados e aplicando os atrasos\n",
    "    result = clf.merge(rtns, how=\"outer\", on=['created_at'])\n",
    "    result['return_lag1'] = result[COMP].shift(1)\n",
    "    result['return_lag3'] = result[COMP].shift(3)\n",
    "    result['return_lag5'] = result[COMP].shift(5)\n",
    "\n",
    "    path = \"clasf_merc_{}.xlsx\".format(COMP)\n",
    "    result.to_excel(path)\n",
    "\n",
    "def overall_corr(COMP_LST):\n",
    "    for comp in COMP_LST:\n",
    "        if comp == 'SP500':\n",
    "            corr_analy(comp, ['$SPX', '$SPY'])\n",
    "        elif comp == 'Microsoft':\n",
    "            corr_analy(comp, ['$MSFT'])\n",
    "        elif comp == 'Amazon':\n",
    "            corr_analy(comp, ['$AMZN'])\n",
    "        elif comp == 'Apple':\n",
    "            corr_analy(comp, ['$AAPL'])\n",
    "        elif comp == 'Meta':\n",
    "            corr_analy(comp, ['$FB'])\n",
    "\n",
    "overall_corr([\"SP500\", \"Microsoft\", \"Amazon\", \"Apple\", \"Meta\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d389d703494463e9315607c677e661bd791ee5f0430021f4e6bfeedc98eeac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
